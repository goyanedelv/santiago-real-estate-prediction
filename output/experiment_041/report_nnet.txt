experiment_041
More hypertuning!

0.25
{'hidden_layer_sizes': [2, 7, 50], 'alpha': [0.0001, 0.001, 0.01], 'activation': ['relu', 'logistic'], 'max_iter': [1000]}
Mape 0.3472445248788282
Mdape 0.2624123115295607
Mae 20.95176833681626
Mape deciles
1.1682501785104853
0.5274343033910891
0.3045088002877503
0.17614454817264466
0.08855855476381248
0.054302329929519826
0.12917249908667766
0.23688214742747496
0.3315541212953167
0.4521710212624365
Mdape deciles
1.0757453225826445
0.5496206266817691
0.3127710774115021
0.18278938651890092
0.08162446160701749
0.02974720278411918
0.12026669707613359
0.23747098089224045
0.3289409058775019
0.43209162136859436
Best parms:{'activation': 'logistic', 'alpha': 0.01, 'hidden_layer_sizes': 50, 'max_iter': 1000}